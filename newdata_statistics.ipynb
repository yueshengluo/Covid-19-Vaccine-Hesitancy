{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\luoyu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\luoyu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "import emoji\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from langdetect import detect\n",
    "nltk.download('punkt')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import gensim\n",
    "nltk.download('vader_lexicon')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## dic for contraction sub\n",
    "CONTRACTION_MAP = {\n",
    "\"ain't\": \"is not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he'll've\": \"he he will have\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'd'y\": \"how do you\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"I'd\": \"I would\",\n",
    "\"I'd've\": \"I would have\",\n",
    "\"I'll\": \"I will\",\n",
    "\"I'll've\": \"I will have\",\n",
    "\"I'm\": \"I am\",\n",
    "\"I've\": \"I have\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'd've\": \"i would have\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'll've\": \"i will have\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'd've\": \"it would have\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it'll've\": \"it will have\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"mightn't've\": \"might not have\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"mustn't've\": \"must not have\",\n",
    "\"needn't\": \"need not\",\n",
    "\"needn't've\": \"need not have\",\n",
    "\"o'clock\": \"of the clock\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"oughtn't've\": \"ought not have\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"shan't've\": \"shall not have\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'd've\": \"she would have\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she'll've\": \"she will have\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"shouldn't've\": \"should not have\",\n",
    "\"so've\": \"so have\",\n",
    "\"so's\": \"so as\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that'd've\": \"that would have\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there would\",\n",
    "\"there'd've\": \"there would have\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'd've\": \"they would have\",   \n",
    "\"they'll\": \"they will\",\n",
    "\"they'll've\": \"they will have\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"to've\": \"to have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'd've\": \"we would have\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we'll've\": \"we will have\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what'll've\": \"what will have\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"when's\": \"when is\",\n",
    "\"when've\": \"when have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"where've\": \"where have\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who'll've\": \"who will have\",\n",
    "\"who's\": \"who is\",\n",
    "\"who've\": \"who have\",\n",
    "\"why's\": \"why is\",\n",
    "\"why've\": \"why have\",\n",
    "\"will've\": \"will have\",\n",
    "\"won't\": \"will not\",\n",
    "\"won't've\": \"will not have\",\n",
    "\"would've\": \"would have\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"wouldn't've\": \"would not have\",\n",
    "\"y'all\": \"you all\",\n",
    "\"y'all'd\": \"you all would\",\n",
    "\"y'all'd've\": \"you all would have\",\n",
    "\"y'all're\": \"you all are\",\n",
    "\"y'all've\": \"you all have\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'd've\": \"you would have\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you'll've\": \"you will have\",\n",
    "\"you're\": \"you are\",\n",
    "\"you've\": \"you have\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## Cleaning methods\n",
    "def clean_emoji(text):\n",
    "    text=emoji.demojize(text)\n",
    "    return text\n",
    "\n",
    "def remove_url(text):\n",
    "    text = ' '.join(re.sub(\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\",\" \", text).split())\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_symbol(text):\n",
    "    text = str.replace(text,',',' ')\n",
    "    text = str.replace(text,'+',' ')\n",
    "    text = str.replace(text,'=',' ')\n",
    "    text = ' '.join(re.sub(\"(\\d{3}[-\\.\\s]??\\d{3}[-\\.\\s]??\\d{4}|\\(\\d{3}\\)\\s*\\d{3}[-\\.\\s]??\\d{4}|\\d{3}[-\\.\\s]??\\d{4})\",\" \", text).split())\n",
    "    text = str.replace(text,\"'\",' ')\n",
    "    text = str.replace(text,'\"',' ')\n",
    "    text = str.replace(text,'!',' ')\n",
    "    text = str.replace(text,'^',' ')\n",
    "    text = str.replace(text,'(',' ')\n",
    "    text = str.replace(text,')',' ')\n",
    "    text = str.replace(text,'%',' ')\n",
    "    text = str.replace(text,'-',' ')\n",
    "    text = str.replace(text,'_',' ')\n",
    "    text = str.replace(text,'|',' ')\n",
    "    text = str.replace(text,'.',' ')\n",
    "    text = str.replace(text,':',' ')\n",
    "    return text\n",
    "    \n",
    "## this is the optional function we can use to remove @ and other. Might not use it if we need to analyze retweets\n",
    "## also set all to lower case\n",
    "def optional_rm(text):\n",
    "    all_words = text.split(' ')\n",
    "    remove_words = []\n",
    "    for each in all_words:\n",
    "        if each == ' ' or each == '':\n",
    "            continue\n",
    "        if each[0] == '#' or each[0] == '@':\n",
    "            remove_words.append(each)\n",
    "    for word in remove_words:\n",
    "        all_words.remove(word)\n",
    "    text = ' '.join(all_words)\n",
    "    \n",
    "    text = text.split(' ')\n",
    "    new_text = []\n",
    "    for each in text:\n",
    "        if(str.find(each,'http') != -1):\n",
    "            continue\n",
    "        \n",
    "        if not each.isalnum():\n",
    "            continue\n",
    "        new_text.append(str.lower(each));\n",
    "    text = ' '.join(new_text)\n",
    "    \n",
    "    return text\n",
    "    \n",
    "def is_english(text):\n",
    "    try:\n",
    "        if detect(text) == \"en\":\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        return True\n",
    "        print(e)\n",
    "    \n",
    "def isEnglish(s):\n",
    "    try:\n",
    "        s.encode(encoding='utf-8').decode('ascii')\n",
    "    except UnicodeDecodeError:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "    \n",
    "def processing(text):\n",
    "    #text=clean_emoji(text)\n",
    "    #text=remove_url(text)\n",
    "    #text = remove_symbol(text)\n",
    "    text = optional_rm(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## Split the data into two parts, one for original tweet txt, another one for tweet txt\n",
    "## drop na \n",
    "## remove the row which tweet_txt has no full text\n",
    "def split_data(dataframe):\n",
    "    df_og=dataframe[['og_tweet_txt', 'og_tweet_time', 'og_tweet_id', 'og_tweet_user_id',\n",
    "       'og_tweet_user_name', 'og_tweet_user_desc', 'og_tweet_user_vrifd',\n",
    "       'og_tweet_user_loc']]\n",
    "    df_tweet=dataframe[['tweet_txt', 'user_loc', 'tweet_geo',\n",
    "       'tweet_place', 'tweet_time', 'tweet_id', 'user_id', 'user_name',\n",
    "       'tweet_likes', 'tweet_source', 'hashtags', 'user_acc_cr_time',\n",
    "       'user_verified', 'user_total_tweets', 'user_followers']]\n",
    "    dt_og=df_og.copy()\n",
    "    dt_og=dt_og.dropna(axis=0,how='any')\n",
    "    dt_og=dt_og[~dt_og['og_tweet_txt'].isin(['\\u2026'])]  \n",
    "    dt_tweet=df_tweet.copy()\n",
    "    # dt_tweet=dt_tweet.dropna(axis=0,how='any')\n",
    "    dt_tweet=dt_tweet[~dt_tweet['tweet_txt'].str.contains('\\u2026')]\n",
    "    \n",
    "    \n",
    "    ## text cleaning\n",
    "#     dt_og['tweet_txt_clean']=dt_og['og_tweet_txt'].apply(lambda x: processing(x))\n",
    "#     dt_tweet['tweet_txt_clean']=dt_tweet['tweet_txt'].apply(lambda x: processing(x))\n",
    "    \n",
    "#     dt_og = dt_og[dt_og[\"tweet_txt_clean\"].apply(is_english)]\n",
    "#     dt_tweet = dt_tweet[dt_tweet[\"tweet_txt_clean\"].apply(is_english)]\n",
    "    \n",
    "    return dt_og, dt_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['02-17-2021.json', '02-18-2021.json', '02-19-2021.json', '02-20-2021.json', '02-21-2021.json', '02-22-2021.json', '02-23-2021.json', '02-24-2021.json']\n",
      "C:/Users/luoyu/Desktop/USCISI/vaccine hesitancy/newdata/02-17-2021.json\n",
      "C:/Users/luoyu/Desktop/USCISI/vaccine hesitancy/newdata/02-18-2021.json\n",
      "C:/Users/luoyu/Desktop/USCISI/vaccine hesitancy/newdata/02-19-2021.json\n",
      "C:/Users/luoyu/Desktop/USCISI/vaccine hesitancy/newdata/02-20-2021.json\n",
      "C:/Users/luoyu/Desktop/USCISI/vaccine hesitancy/newdata/02-21-2021.json\n",
      "C:/Users/luoyu/Desktop/USCISI/vaccine hesitancy/newdata/02-22-2021.json\n",
      "C:/Users/luoyu/Desktop/USCISI/vaccine hesitancy/newdata/02-23-2021.json\n",
      "C:/Users/luoyu/Desktop/USCISI/vaccine hesitancy/newdata/02-24-2021.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(970708, 23)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Import Data\n",
    "def read_json_to_dataframe(filename):\n",
    "    print(filename)\n",
    "    #f = open(filename,encoding = 'utf-16').read()\n",
    "    f1 = pd.read_json(filename, orient='records',lines=True,encoding = 'utf-16')\n",
    "    return f1\n",
    "def read_in(path):\n",
    "    files = os.listdir(path)\n",
    "    all_dfs = []\n",
    "    print(files)\n",
    "    for i in files:\n",
    "        if 'json' in i:\n",
    "            each_df = read_json_to_dataframe(path+i)\n",
    "            all_dfs.append(each_df)\n",
    "            \n",
    "    return pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "all_df = read_in('C:/Users/luoyu/Desktop/USCISI/vaccine hesitancy/newdata/')\n",
    "all_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "## Get rid of the folded tweets\n",
    "test_df = all_df.copy()\n",
    "test_df=test_df[~test_df['og_tweet_txt'].str.endswith('\\u2026',na=True)]\n",
    "test_df=test_df[~((test_df['tweet_txt'].str.endswith('\\u2026',na=True)) & (test_df['og_tweet_txt'].str.strip() == \"\"))]\n",
    "# test_df=test_df.dropna(axis=0,how='any')\n",
    "#test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def clean_txt(df):\n",
    "    df[\"og_tweet_txt\"] = df['og_tweet_txt'].apply(lambda x: processing(x))\n",
    "    print('finish processing retweet')\n",
    "    df['tweet_txt'] = df['tweet_txt'].apply(lambda x: processing(x))\n",
    "    print('finish processing no retweet')\n",
    "    #df[df[\"tweet_txt\"].apply(is_english)]\n",
    "    #df[df[\"og_tweet_txt\"].apply(is_english)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-46b99d98a867>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'tweet_txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"last\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#test_df = test_df.drop_duplicates(subset='og_tweet_txt', keep=\"last\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop_duplicates\u001b[1;34m(self, subset, keep, inplace, ignore_index)\u001b[0m\n\u001b[0;32m   5106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5107\u001b[0m         \u001b[0minplace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_bool_kwarg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"inplace\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5108\u001b[1;33m         \u001b[0mduplicated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5110\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mduplicated\u001b[1;34m(self, subset, keep)\u001b[0m\n\u001b[0;32m   5245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5246\u001b[0m         \u001b[0mvals\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5247\u001b[1;33m         \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5249\u001b[0m         \u001b[0mids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_group_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxnull\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mf\u001b[1;34m(vals)\u001b[0m\n\u001b[0;32m   5219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5220\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5221\u001b[1;33m             labels, shape = algorithms.factorize(\n\u001b[0m\u001b[0;32m   5222\u001b[0m                 \u001b[0mvals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_hint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_SIZE_HINT_LIMIT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5223\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\algorithms.py\u001b[0m in \u001b[0;36mfactorize\u001b[1;34m(values, sort, na_sentinel, size_hint)\u001b[0m\n\u001b[0;32m    675\u001b[0m             \u001b[0mna_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 677\u001b[1;33m         codes, uniques = _factorize_array(\n\u001b[0m\u001b[0;32m    678\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_sentinel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_sentinel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_hint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msize_hint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\algorithms.py\u001b[0m in \u001b[0;36m_factorize_array\u001b[1;34m(values, na_sentinel, size_hint, na_value, mask)\u001b[0m\n\u001b[0;32m    495\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mndarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m     \"\"\"\n\u001b[1;32m--> 497\u001b[1;33m     \u001b[0mhash_klass\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_data_algo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    498\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[0mtable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhash_klass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_hint\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\algorithms.py\u001b[0m in \u001b[0;36m_get_data_algo\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_values_for_rank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m     \u001b[0mndtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_object_for_strings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    267\u001b[0m     \u001b[0mhtable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_hashtables\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mndtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_hashtables\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"object\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_df = test_df.drop_duplicates(subset='tweet_txt', keep=\"last\")\n",
    "#test_df = test_df.drop_duplicates(subset='og_tweet_txt', keep=\"last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-edc904c48e08>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"og_tweet_txt\"] = df['og_tweet_txt'].apply(lambda x: processing(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish processing retweet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-edc904c48e08>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tweet_txt'] = df['tweet_txt'].apply(lambda x: processing(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish processing no retweet\n"
     ]
    }
   ],
   "source": [
    "clean_df = clean_txt(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-41-983449fb880e>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"og_tweet_txt\"] = df['og_tweet_txt'].apply(lambda x: processing(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish processing retweet\n",
      "finish processing no retweet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-41-983449fb880e>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tweet_txt'] = df['tweet_txt'].apply(lambda x: processing(x))\n"
     ]
    }
   ],
   "source": [
    "clean_df = clean_txt(clean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>og_tweet_txt</th>\n",
       "      <th>og_tweet_time</th>\n",
       "      <th>og_tweet_id</th>\n",
       "      <th>og_tweet_user_id</th>\n",
       "      <th>og_tweet_user_name</th>\n",
       "      <th>og_tweet_user_desc</th>\n",
       "      <th>og_tweet_user_vrifd</th>\n",
       "      <th>og_tweet_user_loc</th>\n",
       "      <th>tweet_txt</th>\n",
       "      <th>user_loc</th>\n",
       "      <th>...</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>tweet_likes</th>\n",
       "      <th>tweet_source</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>user_acc_cr_time</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>user_total_tweets</th>\n",
       "      <th>user_followers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>NaT</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>is anyone gonna mention biden forgot he receiv...</td>\n",
       "      <td>On a Lake</td>\n",
       "      <td>...</td>\n",
       "      <td>1362255917085986817</td>\n",
       "      <td>34742700</td>\n",
       "      <td>tinberry</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td></td>\n",
       "      <td>2009-04-23 21:51:32</td>\n",
       "      <td>False</td>\n",
       "      <td>1737</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td>NaT</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>just on presentation alone he should be put in...</td>\n",
       "      <td>Saratoga Springs, NY</td>\n",
       "      <td>...</td>\n",
       "      <td>1362255933586485249</td>\n",
       "      <td>1218151375609180163</td>\n",
       "      <td>SML531974</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td></td>\n",
       "      <td>2020-01-17 12:41:56</td>\n",
       "      <td>False</td>\n",
       "      <td>13152</td>\n",
       "      <td>452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>the spread of highly contagious coronavirus va...</td>\n",
       "      <td>2021-02-16 19:10:06</td>\n",
       "      <td>1361754747880022018</td>\n",
       "      <td>3108351</td>\n",
       "      <td>WSJ</td>\n",
       "      <td>Sign up for our newsletters and email alerts: ...</td>\n",
       "      <td>True</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>rt the spread of highly contagious coronavirus...</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>1362255935285133313</td>\n",
       "      <td>738884622147289088</td>\n",
       "      <td>Lgmcruiser</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td></td>\n",
       "      <td>2016-06-04 00:06:36</td>\n",
       "      <td>False</td>\n",
       "      <td>14130</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td>NaT</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>claire pfizer only enrolled 5 ppl over the age...</td>\n",
       "      <td>World</td>\n",
       "      <td>...</td>\n",
       "      <td>1362255938292314115</td>\n",
       "      <td>796908792093020160</td>\n",
       "      <td>CarmenNasty2016</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td></td>\n",
       "      <td>2016-11-11 02:53:56</td>\n",
       "      <td>False</td>\n",
       "      <td>2238</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td></td>\n",
       "      <td>NaT</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>is this biden s uniqua</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>1362255938405588992</td>\n",
       "      <td>1291573086022639617</td>\n",
       "      <td>BotSatire</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td></td>\n",
       "      <td>2020-08-07 03:13:40</td>\n",
       "      <td>False</td>\n",
       "      <td>1185</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970703</th>\n",
       "      <td>making you get tested for covid before you ent...</td>\n",
       "      <td>2021-02-25 01:41:54</td>\n",
       "      <td>1364752447831375873</td>\n",
       "      <td>1195136746524012544</td>\n",
       "      <td>TrishForTrump</td>\n",
       "      <td>Real Estate Broker...Investor...USA ...”Joe’s ...</td>\n",
       "      <td>False</td>\n",
       "      <td>California, USA</td>\n",
       "      <td>rt making you get tested for covid before you ...</td>\n",
       "      <td>Cyberdyne Systems, Inc.</td>\n",
       "      <td>...</td>\n",
       "      <td>1364847442609336325</td>\n",
       "      <td>2590012027</td>\n",
       "      <td>Algerwins</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td></td>\n",
       "      <td>2014-06-26 17:42:54</td>\n",
       "      <td>False</td>\n",
       "      <td>66110</td>\n",
       "      <td>5216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970704</th>\n",
       "      <td>whose coming partying face partying face party...</td>\n",
       "      <td>2021-02-24 22:19:00</td>\n",
       "      <td>1364701389692280835</td>\n",
       "      <td>83197153</td>\n",
       "      <td>Lyndonx</td>\n",
       "      <td>This is real and raw. Sharing experiences &amp; li...</td>\n",
       "      <td>True</td>\n",
       "      <td>Zapped it</td>\n",
       "      <td>rt whose coming partying face partying face pa...</td>\n",
       "      <td>London</td>\n",
       "      <td>...</td>\n",
       "      <td>1364847445151219714</td>\n",
       "      <td>3003029949</td>\n",
       "      <td>ThemysciranJZ</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td></td>\n",
       "      <td>2015-01-28 12:10:27</td>\n",
       "      <td>False</td>\n",
       "      <td>19948</td>\n",
       "      <td>1262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970705</th>\n",
       "      <td>tremendous flexibility of synthetic biology mo...</td>\n",
       "      <td>2021-02-25 01:48:52</td>\n",
       "      <td>1364754203663564800</td>\n",
       "      <td>282076470</td>\n",
       "      <td>AgBioWorld</td>\n",
       "      <td>Professor, biotech guru. I am curious about sc...</td>\n",
       "      <td>False</td>\n",
       "      <td>Alabama, USA</td>\n",
       "      <td>rt tremendous flexibility of synthetic biology...</td>\n",
       "      <td>Cold Spring Harbor, NY</td>\n",
       "      <td>...</td>\n",
       "      <td>1364847445717504001</td>\n",
       "      <td>1692248610</td>\n",
       "      <td>JasonWilliamsNY</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td></td>\n",
       "      <td>2013-08-22 22:53:04</td>\n",
       "      <td>False</td>\n",
       "      <td>75992</td>\n",
       "      <td>4314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970706</th>\n",
       "      <td>the will receive a batch of 600 000 doses of d...</td>\n",
       "      <td>2021-02-25 06:02:00</td>\n",
       "      <td>1364817905364340739</td>\n",
       "      <td>1115874631</td>\n",
       "      <td>CGTNOfficial</td>\n",
       "      <td>CGTN is an international media organization. I...</td>\n",
       "      <td>True</td>\n",
       "      <td>Beijing, China</td>\n",
       "      <td>rt the will receive a batch of 600 000 doses o...</td>\n",
       "      <td>Republic of Korea</td>\n",
       "      <td>...</td>\n",
       "      <td>1364847445738356738</td>\n",
       "      <td>890916095963430912</td>\n",
       "      <td>Totoyami1</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>Philippines</td>\n",
       "      <td>2017-07-28 12:45:24</td>\n",
       "      <td>False</td>\n",
       "      <td>5696</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970707</th>\n",
       "      <td>syringe ingredients of pfizer covid 19 vaccine</td>\n",
       "      <td>2021-02-24 11:36:01</td>\n",
       "      <td>1364539576208023552</td>\n",
       "      <td>4870788316</td>\n",
       "      <td>DrAmalinaBakri</td>\n",
       "      <td>General Surgeon (Specialist Trainee) &amp; PhD Cli...</td>\n",
       "      <td>True</td>\n",
       "      <td>London, England</td>\n",
       "      <td>rt syringe ingredients of pfizer covid 19 vaccine</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>1364847455867572224</td>\n",
       "      <td>1448594724</td>\n",
       "      <td>safiahmin</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td></td>\n",
       "      <td>2013-05-22 11:01:04</td>\n",
       "      <td>False</td>\n",
       "      <td>53599</td>\n",
       "      <td>1202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>358011 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             og_tweet_txt       og_tweet_time  \\\n",
       "3                                                                         NaT   \n",
       "7                                                                         NaT   \n",
       "8       the spread of highly contagious coronavirus va... 2021-02-16 19:10:06   \n",
       "9                                                                         NaT   \n",
       "10                                                                        NaT   \n",
       "...                                                   ...                 ...   \n",
       "970703  making you get tested for covid before you ent... 2021-02-25 01:41:54   \n",
       "970704  whose coming partying face partying face party... 2021-02-24 22:19:00   \n",
       "970705  tremendous flexibility of synthetic biology mo... 2021-02-25 01:48:52   \n",
       "970706  the will receive a batch of 600 000 doses of d... 2021-02-25 06:02:00   \n",
       "970707     syringe ingredients of pfizer covid 19 vaccine 2021-02-24 11:36:01   \n",
       "\n",
       "                og_tweet_id     og_tweet_user_id og_tweet_user_name  \\\n",
       "3                                                                     \n",
       "7                                                                     \n",
       "8       1361754747880022018              3108351                WSJ   \n",
       "9                                                                     \n",
       "10                                                                    \n",
       "...                     ...                  ...                ...   \n",
       "970703  1364752447831375873  1195136746524012544      TrishForTrump   \n",
       "970704  1364701389692280835             83197153            Lyndonx   \n",
       "970705  1364754203663564800            282076470         AgBioWorld   \n",
       "970706  1364817905364340739           1115874631       CGTNOfficial   \n",
       "970707  1364539576208023552           4870788316     DrAmalinaBakri   \n",
       "\n",
       "                                       og_tweet_user_desc og_tweet_user_vrifd  \\\n",
       "3                                                                               \n",
       "7                                                                               \n",
       "8       Sign up for our newsletters and email alerts: ...                True   \n",
       "9                                                                               \n",
       "10                                                                              \n",
       "...                                                   ...                 ...   \n",
       "970703  Real Estate Broker...Investor...USA ...”Joe’s ...               False   \n",
       "970704  This is real and raw. Sharing experiences & li...                True   \n",
       "970705  Professor, biotech guru. I am curious about sc...               False   \n",
       "970706  CGTN is an international media organization. I...                True   \n",
       "970707  General Surgeon (Specialist Trainee) & PhD Cli...                True   \n",
       "\n",
       "       og_tweet_user_loc                                          tweet_txt  \\\n",
       "3                         is anyone gonna mention biden forgot he receiv...   \n",
       "7                         just on presentation alone he should be put in...   \n",
       "8           New York, NY  rt the spread of highly contagious coronavirus...   \n",
       "9                         claire pfizer only enrolled 5 ppl over the age...   \n",
       "10                                                   is this biden s uniqua   \n",
       "...                  ...                                                ...   \n",
       "970703   California, USA  rt making you get tested for covid before you ...   \n",
       "970704         Zapped it  rt whose coming partying face partying face pa...   \n",
       "970705      Alabama, USA  rt tremendous flexibility of synthetic biology...   \n",
       "970706    Beijing, China  rt the will receive a batch of 600 000 doses o...   \n",
       "970707   London, England  rt syringe ingredients of pfizer covid 19 vaccine   \n",
       "\n",
       "                       user_loc  ...             tweet_id  \\\n",
       "3                     On a Lake  ...  1362255917085986817   \n",
       "7          Saratoga Springs, NY  ...  1362255933586485249   \n",
       "8                          None  ...  1362255935285133313   \n",
       "9                         World  ...  1362255938292314115   \n",
       "10                         None  ...  1362255938405588992   \n",
       "...                         ...  ...                  ...   \n",
       "970703  Cyberdyne Systems, Inc.  ...  1364847442609336325   \n",
       "970704                   London  ...  1364847445151219714   \n",
       "970705   Cold Spring Harbor, NY  ...  1364847445717504001   \n",
       "970706        Republic of Korea  ...  1364847445738356738   \n",
       "970707                     None  ...  1364847455867572224   \n",
       "\n",
       "                    user_id        user_name  tweet_likes  \\\n",
       "3                  34742700         tinberry            0   \n",
       "7       1218151375609180163        SML531974            0   \n",
       "8        738884622147289088       Lgmcruiser            0   \n",
       "9        796908792093020160  CarmenNasty2016            0   \n",
       "10      1291573086022639617        BotSatire            0   \n",
       "...                     ...              ...          ...   \n",
       "970703           2590012027        Algerwins            0   \n",
       "970704           3003029949    ThemysciranJZ            0   \n",
       "970705           1692248610  JasonWilliamsNY            0   \n",
       "970706   890916095963430912        Totoyami1            0   \n",
       "970707           1448594724        safiahmin            0   \n",
       "\n",
       "               tweet_source     hashtags    user_acc_cr_time user_verified  \\\n",
       "3           Twitter Web App              2009-04-23 21:51:32         False   \n",
       "7       Twitter for Android              2020-01-17 12:41:56         False   \n",
       "8        Twitter for iPhone              2016-06-04 00:06:36         False   \n",
       "9           Twitter Web App              2016-11-11 02:53:56         False   \n",
       "10          Twitter Web App              2020-08-07 03:13:40         False   \n",
       "...                     ...          ...                 ...           ...   \n",
       "970703      Twitter Web App              2014-06-26 17:42:54         False   \n",
       "970704      Twitter Web App              2015-01-28 12:10:27         False   \n",
       "970705   Twitter for iPhone              2013-08-22 22:53:04         False   \n",
       "970706  Twitter for Android  Philippines 2017-07-28 12:45:24         False   \n",
       "970707  Twitter for Android              2013-05-22 11:01:04         False   \n",
       "\n",
       "       user_total_tweets user_followers  \n",
       "3                   1737             21  \n",
       "7                  13152            452  \n",
       "8                  14130             27  \n",
       "9                   2238             39  \n",
       "10                  1185            153  \n",
       "...                  ...            ...  \n",
       "970703             66110           5216  \n",
       "970704             19948           1262  \n",
       "970705             75992           4314  \n",
       "970706              5696              8  \n",
       "970707             53599           1202  \n",
       "\n",
       "[358011 rows x 23 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.to_pickle(\"./cleaned_strip@.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(970708, 23)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
