{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\luoyu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\luoyu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#packages\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "import emoji\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from langdetect import detect\n",
    "nltk.download('punkt')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import gensim\n",
    "nltk.download('vader_lexicon')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix, hstack\n",
    "from scipy.sparse import csr_matrix\n",
    "import sklearn\n",
    "from scipy import spatial\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "import gensim.downloader\n",
    "import fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#import sentiments prediction result from lstm\n",
    "lstm_pred = pd.read_csv(r\"C:\\Users\\luoyu\\Desktop\\USCISI\\vaccine hesitancy\\lstm_pred\\LSTM_prediction.csv\")\n",
    "lstm_pred = lstm_pred[lstm_pred['combined_tweet_txt'].notna()]\n",
    "lstm_pred = lstm_pred.drop_duplicates(subset='combined_tweet_txt', keep=\"last\")\n",
    "list_of_txt = list(lstm_pred[\"combined_tweet_txt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-64e7df3fd2bb>:4: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n",
      "  w2v = dict(zip(model.wv.index2word, model.wv.syn0))\n",
      "<ipython-input-4-64e7df3fd2bb>:7: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  glove_vectors_w2v = dict(zip(glove_vectors.wv.index2word, glove_vectors.wv.syn0))\n",
      "<ipython-input-4-64e7df3fd2bb>:7: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n",
      "  glove_vectors_w2v = dict(zip(glove_vectors.wv.index2word, glove_vectors.wv.syn0))\n"
     ]
    }
   ],
   "source": [
    "#train word2vec with Gensim and import glove\n",
    "tokens = [nltk.word_tokenize(sentences) for sentences in list_of_txt]\n",
    "model = gensim.models.Word2Vec(tokens, min_count=1, size=25) \n",
    "w2v = dict(zip(model.wv.index2word, model.wv.syn0))\n",
    "\n",
    "glove_vectors = gensim.downloader.load('glove-twitter-25')\n",
    "glove_vectors_w2v = dict(zip(glove_vectors.wv.index2word, glove_vectors.wv.syn0))\n",
    "w2v.update(glove_vectors_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train word2vec with Fasttext\n",
    "from gensim.models import FastText\n",
    "FasTxt = FastText(list_of_txt, size=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_vectors = gensim.downloader.load('glove-twitter-25')\n",
    "glove_vectors_w2v = dict(zip(glove_vectors.wv.index2word, glove_vectors.wv.syn0))\n",
    "FasTxt.update(glove_vectors_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#sentence embedding\n",
    "def embedding(list_of_txt, model,size):\n",
    "    Tfidf_model = TfidfVectorizer()\n",
    "    Tfidf_model.fit(list_of_txt)\n",
    "    tf_idf_dict = dict(zip(Tfidf_model.get_feature_names(), list(Tfidf_model.idf_)))\n",
    "    documents = []\n",
    "    for count,tweet in enumerate(list_of_txt):\n",
    "    #word_vectors = []\n",
    "        weight_sum = 0\n",
    "        for word in tokens[count]: # or your logic for separating tokens\n",
    "            sent_vec = np.zeros(size)\n",
    "            if word in tf_idf_dict:\n",
    "                tf_idf_score = tf_idf_dict[word]\n",
    "                sent_vec += model[word]*tf_idf_score\n",
    "                weight_sum += tf_idf_score\n",
    "                #word_vectors.append(sent_vec)\n",
    "        if weight_sum != 0:\n",
    "            sent_vec /= weight_sum\n",
    "        documents.append(sent_vec)\n",
    "    return documents \n",
    "documents = embedding(list_of_txt,w2v,25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "##add word2vec vectors to lstm_pred column\n",
    "lstm_pred['wordvec'] = documents\n",
    "##filter the negative sentiment tweets\n",
    "lstm_pred_negative = lstm_pred.copy().loc[lstm_pred['prediction'] == -1]\n",
    "lstm_pred_negative['word_len'] = lstm_pred_negative['combined_tweet_txt'].str.len()\n",
    "lstm_pred_negative.to_excel('lstm_pred_negative.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#import manual labeled cluster samples from Bi Topic Modeling result and clean\n",
    "cluster_sample = pd.read_excel(r\"C:\\Users\\luoyu\\Desktop\\USCISI\\vaccine hesitancy\\cluster_sample_txt.xlsx\")\n",
    "cluster_sample = cluster_sample.drop_duplicates(subset='combined_tweet_txt', keep=\"last\")\n",
    "cluster_sample = cluster_sample[cluster_sample['class'].notna()]\n",
    "cluster_sample = cluster_sample[['class','combined_tweet_txt']]\n",
    "#lstm_pred = lstm_pred.drop_duplicates(subset='combined_tweet_txt', keep=\"last\")\n",
    "\n",
    "##join with lstm_pred on combined text\n",
    "cluster_joined = cluster_sample.set_index('combined_tweet_txt').join(lstm_pred.set_index('combined_tweet_txt'), how='left')\n",
    "cluster_joined = cluster_joined.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luoyu\\anaconda3\\lib\\site-packages\\scipy\\spatial\\distance.py:714: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103854    volunteer ronavirus vaccine trial dies brazil ...\n",
      "Name: combined_tweet_txt, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>andrew cuomo americans skeptical ronavirus vaccine based players government nobody knowsandrew cuomo americans skeptical ronavirus vaccine based players government nobody knows trust via</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>who says 184 untries joined vax vaccine program via</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vid 19 may never disappear even vaccine vallance says sent via vid 19 may never disappear even vaccine vallance says sent via</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vid firm secures infect young volunteers hasten vaccine via</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vid 19 may never disappear even vaccine vallance says sent via</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>usa plandemic ronavirus 5g vaccine deception full documentary via usa plandemic ronavirus 5g vaccine deception full documentary via</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>astrazeneca vid 19 vaccine trial volunteer died brazil health authority says arab news via</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a paicipant astrazeneca clinical trial vaccine paicipant apparently get thea paicipant astrazeneca clinical trial vaccine paicipant apparently get vaccine local newspapers claim paicipant died vid 19 mplications via</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a volunteer astrazeneca ronavirus vaccine trial died via</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volunteer astrazeneca oxford vid 19 vaccine trial died brazil health authority says via</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0\n",
       "andrew cuomo americans skeptical ronavirus vacc...  1.0\n",
       "who says 184 untries joined vax vaccine program...  1.0\n",
       "vid 19 may never disappear even vaccine vallanc...  1.0\n",
       "vid firm secures infect young volunteers hasten...  1.0\n",
       "vid 19 may never disappear even vaccine vallanc...  1.0\n",
       "usa plandemic ronavirus 5g vaccine deception fu...  1.0\n",
       "astrazeneca vid 19 vaccine trial volunteer died...  1.0\n",
       "a paicipant astrazeneca clinical trial vaccine ...  1.0\n",
       "a volunteer astrazeneca ronavirus vaccine trial...  1.0\n",
       "volunteer astrazeneca oxford vid 19 vaccine tri...  1.0"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## test sentence embedding with cosine similarity \n",
    "##pick a sample tweet and calculate its similarity with the rest of the tweet in cluster_sample--BTM. Examine if the top ranked similar tweets are actually similar with the sample tweet\n",
    "sample_text = lstm_pred_negative[lstm_pred_negative.combined_tweet_txt == 'volunteer ronavirus vaccine trial dies brazil via volunteer ronavirus vaccine trial dies brazil via']\n",
    "sample_wordvec = list(sample_text['wordvec'])[0]\n",
    "sample_text = sample_text['combined_tweet_txt']\n",
    "#sample_text = list(cluster_joined['combined_tweet_txt'])[18]\n",
    "columns_names = ['tweet_id','text_a','similarity','wordvec']\n",
    "dict_sim = {}\n",
    "for i, row in lstm_pred_negative.iterrows():\n",
    "    result = 1 - spatial.distance.cosine(row.wordvec, sample_wordvec)\n",
    "    if result < 1:\n",
    "        dict_sim[row.combined_tweet_txt] = result\n",
    "\n",
    "print(sample_text)\n",
    "#rank similarity and show top n most similar tweets\n",
    "similarity_df = pd.DataFrame.from_dict({k: v for k, v in sorted(dict_sim.items(), key=lambda item: item[1],reverse=True)},orient='index')\n",
    "similarity_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kmeans Cluster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#import manual picked cluster center for initialization \n",
    "cluster_centers = pd.read_excel(r\"C:\\Users\\luoyu\\Desktop\\USCISI\\vaccine hesitancy\\cluster_center_txt.xlsx\")\n",
    "cluster_centers = cluster_centers[['class','combined_tweet_txt']]\n",
    "#join cluster_centers with lstm_pred_negative to add word vectors\n",
    "centers_joined = cluster_centers.set_index('combined_tweet_txt').join(lstm_pred_negative.set_index('combined_tweet_txt'), how='left')\n",
    "centers_joined = centers_joined.reset_index()\n",
    "centers = list(centers_joined['wordvec'])\n",
    "\n",
    "#exclude short text (len<=50), preparation, short text cannot be used to manualy verify claster performance\n",
    "lstm_pred_negative_long = lstm_pred_negative[lstm_pred_negative.word_len > 40]\n",
    "X = list(lstm_pred_negative_long['wordvec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 3899\n",
      "2 2989\n",
      "3 1596\n",
      "4 1486\n",
      "5 4541\n",
      "6 490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-86cba8520f61>:2: RuntimeWarning: Explicit initial center position passed: performing only one init in k-means instead of n_init=10\n",
      "  kmeans = KMeans(init = np.array(centers), n_clusters=6, random_state=5).fit(X)\n"
     ]
    }
   ],
   "source": [
    "##run kmeans with selected centers for initialization\n",
    "kmeans = KMeans(init = np.array(centers), n_clusters=6, random_state=5).fit(X)\n",
    "predict =[i+1 for i in kmeans.labels_]\n",
    "cluster_df = lstm_pred_negative_long.copy()\n",
    "cluster_df['cluster'] = predict\n",
    "\n",
    "#print cluster size\n",
    "for n in range(6):\n",
    "    print(n+1,len([i for i in predict if i == n+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10-19-2020.json', '10-20-2020.json', '10-21-2020.json', '10-22-2020.json', '10-23-2020.json', '10-24-2020.json', '10-25-2020.json']\n",
      "C:/Users/luoyu/Desktop/USCISI/vaccine hesitancy/raw/10-19-2020.json\n",
      "C:/Users/luoyu/Desktop/USCISI/vaccine hesitancy/raw/10-20-2020.json\n",
      "C:/Users/luoyu/Desktop/USCISI/vaccine hesitancy/raw/10-21-2020.json\n",
      "C:/Users/luoyu/Desktop/USCISI/vaccine hesitancy/raw/10-22-2020.json\n",
      "C:/Users/luoyu/Desktop/USCISI/vaccine hesitancy/raw/10-23-2020.json\n",
      "C:/Users/luoyu/Desktop/USCISI/vaccine hesitancy/raw/10-24-2020.json\n",
      "C:/Users/luoyu/Desktop/USCISI/vaccine hesitancy/raw/10-25-2020.json\n"
     ]
    }
   ],
   "source": [
    "#load all dictionary to add precleaned txt, prepare for manual verification of cluster result\n",
    "def read_json_to_dataframe(filename):\n",
    "    print(filename)\n",
    "    #f = open(filename,encoding = 'utf-16').read()\n",
    "    f1 = pd.read_json(filename, orient='records',lines=True,encoding = 'utf-16')\n",
    "    return f1\n",
    "def read_in(path):\n",
    "    files = os.listdir(path)\n",
    "    all_dfs = []\n",
    "    print(files)\n",
    "    for i in files:\n",
    "        if 'json' in i:\n",
    "            each_df = read_json_to_dataframe(path+i)\n",
    "            all_dfs.append(each_df)\n",
    "            \n",
    "    return pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "all_df = read_in('C:/Users/luoyu/Desktop/USCISI/vaccine hesitancy/raw/')\n",
    "all_df = all_df[['og_tweet_txt','tweet_txt','tweet_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = lstm_pred.sample(100)\n",
    "sample = sample.set_index('tweet_id').join(all_df.set_index('tweet_id'), how='left')\n",
    "lstm_pred_negative = lstm_pred.copy().loc[lstm_pred['prediction'] == -1]\n",
    "negative_sample = lstm_pred_negative.sample(100)\n",
    "negative_sample = negative_sample.set_index('tweet_id').join(all_df.set_index('tweet_id'), how='left')\n",
    "sample.to_excel('./sentiment_test_sample.xlsx')\n",
    "negative_sample.to_excel('./sentiment_test_negative_sample.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#join cluster_df with all_df for cluster pre-cleand text\n",
    "cluster_df = cluster_df.set_index('tweet_id').join(all_df.set_index('tweet_id'), how='left')\n",
    "cluster_df = cluster_df.reset_index()[['tweet_id','combined_tweet_txt','cluster','og_tweet_txt','tweet_txt']]\n",
    "#save cluster result to excel for manul verification\n",
    "cluster_df_sample = cluster_df.groupby('cluster').apply(lambda x: x.sample(100))\n",
    "cluster_df_sample.to_excel('cluster_df_sample_6x100_2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1318287612638072832\n"
     ]
    }
   ],
   "source": [
    "for i in list(all_df['tweet_id']):\n",
    "    if '1318287612638072832' in str(i):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>combined_tweet_txt</th>\n",
       "      <th>cluster</th>\n",
       "      <th>og_tweet_txt</th>\n",
       "      <th>tweet_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1318287612638072832</td>\n",
       "      <td>it never fails amaze stupid proclaimed clever ...</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>It never fails to amaze me how stupid some pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1318287821162119169</td>\n",
       "      <td>that insane paisan talk americans even politic...</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>That is insane partisan talk  and all American...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1318287901315256323</td>\n",
       "      <td>jim due respect take vaccine virus better 99</td>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>@JrLaslett @EmeraldRobinson Jim, with all due ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1318288044349423616</td>\n",
       "      <td>struggling get flu vaccine never mind one vid</td>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td>@guardian We’re struggling to get the flu vacc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1318288127849627648</td>\n",
       "      <td>it appears 14 year old girl may developed vacc...</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>It appears that a 14 year old girl may have de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>1320268486753411073</td>\n",
       "      <td>vid 19 vaccine provokes like phase 3 trial vac...</td>\n",
       "      <td>6</td>\n",
       "      <td>Moderna’s COVID-19 Vaccine Provokes ‘COVID-Lik...</td>\n",
       "      <td>RT @NVICLoeDown: Moderna’s COVID-19 Vaccine Pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>1320268788139393024</td>\n",
       "      <td>ronavirus vaccine update launches ronil drug c...</td>\n",
       "      <td>6</td>\n",
       "      <td>Coronavirus vaccine update: #Patanjali launche...</td>\n",
       "      <td>RT @bsindia: Coronavirus vaccine update: #Pata...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>1320268842287837185</td>\n",
       "      <td>i vid trial paicipant please nsider joining study</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>I am a Covid trial participant, please   consi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>1320268883056623616</td>\n",
       "      <td>major vaccine mpany whistleblower says new rna...</td>\n",
       "      <td>6</td>\n",
       "      <td>Major vaccine company WHISTLEBLOWER says the n...</td>\n",
       "      <td>RT @LotusOak2: Major vaccine company WHISTLEBL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15000</th>\n",
       "      <td>1320268884545593345</td>\n",
       "      <td>new post vid 19 vaccine trial paicipant astraz...</td>\n",
       "      <td>2</td>\n",
       "      <td>New post COVID-19 vaccine trial participant DI...</td>\n",
       "      <td>RT @SGTreport: New post COVID-19 vaccine trial...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15001 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  tweet_id                                 combined_tweet_txt  \\\n",
       "0      1318287612638072832  it never fails amaze stupid proclaimed clever ...   \n",
       "1      1318287821162119169  that insane paisan talk americans even politic...   \n",
       "2      1318287901315256323       jim due respect take vaccine virus better 99   \n",
       "3      1318288044349423616      struggling get flu vaccine never mind one vid   \n",
       "4      1318288127849627648  it appears 14 year old girl may developed vacc...   \n",
       "...                    ...                                                ...   \n",
       "14996  1320268486753411073  vid 19 vaccine provokes like phase 3 trial vac...   \n",
       "14997  1320268788139393024  ronavirus vaccine update launches ronil drug c...   \n",
       "14998  1320268842287837185  i vid trial paicipant please nsider joining study   \n",
       "14999  1320268883056623616  major vaccine mpany whistleblower says new rna...   \n",
       "15000  1320268884545593345  new post vid 19 vaccine trial paicipant astraz...   \n",
       "\n",
       "       cluster                                       og_tweet_txt  \\\n",
       "0            2                                                      \n",
       "1            1                                                      \n",
       "2            4                                                      \n",
       "3            6                                                      \n",
       "4            2                                                      \n",
       "...        ...                                                ...   \n",
       "14996        6  Moderna’s COVID-19 Vaccine Provokes ‘COVID-Lik...   \n",
       "14997        6  Coronavirus vaccine update: #Patanjali launche...   \n",
       "14998        2                                                      \n",
       "14999        6  Major vaccine company WHISTLEBLOWER says the n...   \n",
       "15000        2  New post COVID-19 vaccine trial participant DI...   \n",
       "\n",
       "                                               tweet_txt  \n",
       "0      It never fails to amaze me how stupid some pro...  \n",
       "1      That is insane partisan talk  and all American...  \n",
       "2      @JrLaslett @EmeraldRobinson Jim, with all due ...  \n",
       "3      @guardian We’re struggling to get the flu vacc...  \n",
       "4      It appears that a 14 year old girl may have de...  \n",
       "...                                                  ...  \n",
       "14996  RT @NVICLoeDown: Moderna’s COVID-19 Vaccine Pr...  \n",
       "14997  RT @bsindia: Coronavirus vaccine update: #Pata...  \n",
       "14998  I am a Covid trial participant, please   consi...  \n",
       "14999  RT @LotusOak2: Major vaccine company WHISTLEBL...  \n",
       "15000  RT @SGTreport: New post COVID-19 vaccine trial...  \n",
       "\n",
       "[15001 rows x 5 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>combined_tweet_txt</th>\n",
       "      <th>class</th>\n",
       "      <th>kmean_predict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>elon musk take vid vaccine calls bill gates ne...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>drink ol aid take vaccine cuomo fda thinks ame...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dictator newsom california denying freedom cho...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dictator newsom california denying freedom cho...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arrow uk elon musk take vid vaccine calls bill...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>k ronavirus probably never disappear vaccine s...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>everyone please retweet asymptomatic carriers ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>from flu ye came unto flu ye shall return rona...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a vid 19 vaccine unlikely fully stop spread vi...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>it woh reflecting one human disease truly erad...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>well said getting fairly sick people banging h...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>yeah smallpox vaccination vaccine lords tryna ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>i getting vaccine virus 99 5 survival rate</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>during phase 1 trial mrna 1273 vaccine eight 4...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>white heavy check mark good news dr fauci seni...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>uk taps open orphan explore vaccine trials inf...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>breaking volunteer vaccine died tragic deaths ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>so get fellow ntrol group dies injected existi...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>johnson johnson pauses phase 3 vid 19 vaccine ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>given recent pause vid vaccine trial changes c...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>clouseau given recent pause vid vaccine trial ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>letter urging vid 19 vaccine trial paicipation...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>this aicle long g please read gives details mu...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>this aicle long g please read gives details mu...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>if ncern 19 vaccine read awesome aicle learn s...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>i ask question least three times week last thr...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>tolan id rather take live</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3 billion people uld struggle get vid 19 vacci...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>the vid 19 vaccine mark beast 666 nano technol...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>f science</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>americans skeptical anyone pushed us by</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>taking chance trials thank us trial</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>pax dismissed accepted casualty of</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>nerd face retweet reload repeatedly nerd face</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>omg right flushed face netherlands exposes tru...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>the death squad</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>trump baby clown face goblin still inexcusable</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>are brits skull</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>please watch ignore twitter warning truth vid ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>cuomo americans skeptical vid 19 vaccine news ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>gov americans skeptical vid vaccine clear use ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>gov newsom added ncerns vid 19 vaccines said s...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>andrew cuomo americans skeptical ronavirus vac...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>andrew cuomo americans skeptical ronavirus vac...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>cuomo says americans skeptical ronavirus vacci...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>california governor newsom going health expes ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>flu cases getting flu vaccine also getting vac...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>please good gps week bouquet</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>south korea five people died getting flu shots...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>five south koreans die getting flu shots spark...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>i done vid gaslighting fear mongering mask wea...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>no vaccine me</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>this absolute garbage basis provide vaccine no...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>there vaccine</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2 infection provide long term immunity vid vac...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>but vaccine</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>who needs vaccine u mutual respect needs vacci...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   combined_tweet_txt  class  kmean_predict\n",
       "0   elon musk take vid vaccine calls bill gates ne...    1.0              5\n",
       "1   drink ol aid take vaccine cuomo fda thinks ame...    1.0              2\n",
       "2   dictator newsom california denying freedom cho...    1.0              5\n",
       "3   dictator newsom california denying freedom cho...    1.0              5\n",
       "4   arrow uk elon musk take vid vaccine calls bill...    1.0              5\n",
       "5   k ronavirus probably never disappear vaccine s...    2.0              5\n",
       "6   everyone please retweet asymptomatic carriers ...    4.0              5\n",
       "7   from flu ye came unto flu ye shall return rona...    2.0              5\n",
       "8   a vid 19 vaccine unlikely fully stop spread vi...    2.0              5\n",
       "9   it woh reflecting one human disease truly erad...    2.0              4\n",
       "10  well said getting fairly sick people banging h...    2.0              3\n",
       "11  yeah smallpox vaccination vaccine lords tryna ...    2.0              2\n",
       "12         i getting vaccine virus 99 5 survival rate    7.0              3\n",
       "13  during phase 1 trial mrna 1273 vaccine eight 4...    3.0              5\n",
       "14  white heavy check mark good news dr fauci seni...    3.0              5\n",
       "15  uk taps open orphan explore vaccine trials inf...    3.0              5\n",
       "16  breaking volunteer vaccine died tragic deaths ...    3.0              5\n",
       "17  so get fellow ntrol group dies injected existi...    3.0              4\n",
       "18  johnson johnson pauses phase 3 vid 19 vaccine ...    3.0              2\n",
       "19  given recent pause vid vaccine trial changes c...    3.0              5\n",
       "20  clouseau given recent pause vid vaccine trial ...    3.0              5\n",
       "21  letter urging vid 19 vaccine trial paicipation...    3.0              5\n",
       "22  this aicle long g please read gives details mu...    4.0              5\n",
       "23  this aicle long g please read gives details mu...    4.0              5\n",
       "24  if ncern 19 vaccine read awesome aicle learn s...    4.0              3\n",
       "25  i ask question least three times week last thr...    7.0              5\n",
       "26                          tolan id rather take live    7.0              2\n",
       "27  3 billion people uld struggle get vid 19 vacci...    7.0              1\n",
       "28  the vid 19 vaccine mark beast 666 nano technol...    6.0              5\n",
       "29                                          f science    6.0              2\n",
       "30            americans skeptical anyone pushed us by    6.0              2\n",
       "31                taking chance trials thank us trial    4.0              3\n",
       "32                 pax dismissed accepted casualty of    6.0              2\n",
       "33      nerd face retweet reload repeatedly nerd face    4.0              1\n",
       "34  omg right flushed face netherlands exposes tru...    4.0              5\n",
       "35                                    the death squad    4.0              2\n",
       "36     trump baby clown face goblin still inexcusable    4.0              4\n",
       "37                                    are brits skull    4.0              2\n",
       "38  please watch ignore twitter warning truth vid ...    4.0              3\n",
       "39  cuomo americans skeptical vid 19 vaccine news ...    1.0              1\n",
       "40  gov americans skeptical vid vaccine clear use ...    1.0              1\n",
       "41  gov newsom added ncerns vid 19 vaccines said s...    1.0              5\n",
       "42  andrew cuomo americans skeptical ronavirus vac...    6.0              2\n",
       "43  andrew cuomo americans skeptical ronavirus vac...    6.0              2\n",
       "44  cuomo says americans skeptical ronavirus vacci...    6.0              5\n",
       "45  california governor newsom going health expes ...    1.0              1\n",
       "46  flu cases getting flu vaccine also getting vac...    6.0              2\n",
       "47                       please good gps week bouquet    1.0              1\n",
       "48  south korea five people died getting flu shots...    3.0              5\n",
       "49  five south koreans die getting flu shots spark...    3.0              3\n",
       "50  i done vid gaslighting fear mongering mask wea...    5.0              5\n",
       "51                                      no vaccine me    5.0              2\n",
       "52  this absolute garbage basis provide vaccine no...    5.0              5\n",
       "53                                      there vaccine    5.0              4\n",
       "54  2 infection provide long term immunity vid vac...    2.0              5\n",
       "55                                        but vaccine    2.0              4\n",
       "56  who needs vaccine u mutual respect needs vacci...    7.0              2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_joined.drop_duplicates(subset='class', keep=\"first\")\n",
    "cluster_joined['kmean_predict'] = kmeans.predict(list(cluster_joined['wordvec']))\n",
    "cluster_joined[['combined_tweet_txt','class','kmean_predict']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "##load manually varified labeled claster result, and calculate accuracy,recall,precision,f1. stats table in cluster_sample_ana\n",
    "cluster_df_sample_6x100 = pd.read_excel(r\"C:\\Users\\luoyu\\Desktop\\USCISI\\vaccine hesitancy\\cluster_df_sample_6x100.xlsx\")\n",
    "cluster_sample_ana= pd.DataFrame()\n",
    "cluster_sample_ana['clusters']= [1,2,3,4,5,6]\n",
    "cluster_sample_ana['cluster_names'] = ['Negative influence','Efficacy of the vaccines','Negative vaccine trial news','Distrust toward government and vaccine  research','Blatantly refuse',' Covid-19 is common flu']\n",
    "accuracy,precision,recall,f1 = [],[],[],[]\n",
    "tpl,fpl,fnl,tnl = [],[],[],[]\n",
    "true_number = []\n",
    "\n",
    "for i in range(6):\n",
    "    single_cluster = cluster_df_sample_6x100[cluster_df_sample_6x100.cluster == i+1]\n",
    "    single_class = cluster_df_sample_6x100[cluster_df_sample_6x100.true_class == i+1]\n",
    "    true_number.append(len(single_class))\n",
    "    tp = sum([1 for n,m in zip(list(single_cluster.cluster),list(single_cluster.true_class)) if n==m])\n",
    "    fp = 100-tp\n",
    "    fn = len(single_class)-tp\n",
    "    tn = 500 - fn\n",
    "    \n",
    "    tpl.append(tp)\n",
    "    fnl.append(fn)\n",
    "    fpl.append(fp)\n",
    "    tnl.append(tn)\n",
    "    testy = [1 for n in list(single_cluster.cluster)]\n",
    "    yhat_classes = [1 if n==i+1 else 0 for n in list(single_cluster.true_class)]\n",
    "    accuracy.append((tp + tn) / 600)\n",
    "    precision.append(tp/(tp+fp))\n",
    "    recall.append(tp/(tp+fn))\n",
    "    f1.append(2*tp/(2*tp+fp+fn))\n",
    "    #accracy.append(tp/100)\n",
    "\n",
    "cluster_sample_ana['true_number'] = true_number\n",
    "cluster_sample_ana['accuracy'] = accuracy\n",
    "cluster_sample_ana['recall'] = recall\n",
    "cluster_sample_ana['precision'] = precision\n",
    "cluster_sample_ana['f1'] = f1\n",
    "cluster_sample_ana['tp'] = tpl\n",
    "cluster_sample_ana['fn'] = fnl\n",
    "cluster_sample_ana['fp'] = fpl\n",
    "cluster_sample_ana['tn'] = tnl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clusters</th>\n",
       "      <th>cluster_names</th>\n",
       "      <th>true_number</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1</th>\n",
       "      <th>tp</th>\n",
       "      <th>fn</th>\n",
       "      <th>fp</th>\n",
       "      <th>tn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Negative influence</td>\n",
       "      <td>42</td>\n",
       "      <td>0.803333</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.169014</td>\n",
       "      <td>12</td>\n",
       "      <td>30</td>\n",
       "      <td>88</td>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Efficacy of the vaccines</td>\n",
       "      <td>76</td>\n",
       "      <td>0.736667</td>\n",
       "      <td>0.118421</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.102273</td>\n",
       "      <td>9</td>\n",
       "      <td>67</td>\n",
       "      <td>91</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Negative vaccine trial news</td>\n",
       "      <td>145</td>\n",
       "      <td>0.668333</td>\n",
       "      <td>0.158621</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.187755</td>\n",
       "      <td>23</td>\n",
       "      <td>122</td>\n",
       "      <td>77</td>\n",
       "      <td>378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Distrust toward government and vaccine  research</td>\n",
       "      <td>81</td>\n",
       "      <td>0.751667</td>\n",
       "      <td>0.197531</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.176796</td>\n",
       "      <td>16</td>\n",
       "      <td>65</td>\n",
       "      <td>84</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Blatantly refuse</td>\n",
       "      <td>12</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>98</td>\n",
       "      <td>490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Covid-19 is common flu</td>\n",
       "      <td>16</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>96</td>\n",
       "      <td>488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   clusters                                     cluster_names  true_number  accuracy    recall  \\\n",
       "0         1                                Negative influence           42  0.803333  0.285714   \n",
       "1         2                          Efficacy of the vaccines           76  0.736667  0.118421   \n",
       "2         3                       Negative vaccine trial news          145  0.668333  0.158621   \n",
       "3         4  Distrust toward government and vaccine  research           81  0.751667  0.197531   \n",
       "4         5                                  Blatantly refuse           12  0.820000  0.166667   \n",
       "5         6                            Covid-19 is common flu           16  0.820000  0.250000   \n",
       "\n",
       "   precision        f1  tp   fn  fp   tn  \n",
       "0       0.12  0.169014  12   30  88  470  \n",
       "1       0.09  0.102273   9   67  91  433  \n",
       "2       0.23  0.187755  23  122  77  378  \n",
       "3       0.16  0.176796  16   65  84  435  \n",
       "4       0.02  0.035714   2   10  98  490  \n",
       "5       0.04  0.068966   4   12  96  488  "
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_sample_ana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#biclass classification\n",
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid,valid_y,thresh):\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    predicted_proba = classifier.predict_proba(feature_vector_valid)\n",
    "    predictions = (predicted_proba [:,1] >= thresh).astype('int')\n",
    "    \n",
    "    labels = np.unique(label)\n",
    "\n",
    "    report = classification_report(valid_y,predictions,labels = labels,output_dict =True)\n",
    "    \n",
    "    return report\n",
    "\n",
    "def train_classifier(X_train, y_train, X_valid,valid_y,thresh):\n",
    "    report_list=[]\n",
    "    for classifier, flag in zip(test_classifiers, test_classifiers_flag):\n",
    "        report=train_model(classifier, X_train, y_train, X_valid,valid_y,thresh)\n",
    "        #print('------------------The report of',flag,'--------------------')\n",
    "        #print(report)\n",
    "        #print(conf)\n",
    "        report_list.append((flag,report))\n",
    "    return report_list\n",
    "\n",
    "def StratifiedSampling(df, test_size):\n",
    "    X = df.drop(['y'], axis=1)\n",
    "    y = df.y\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=0)    \n",
    "    sss.get_n_splits(X, y)\n",
    "    for train_index, test_index in sss.split(X, y):\n",
    "        train = df.iloc[train_index,:]\n",
    "        test = df.iloc[test_index,:]\n",
    "    return train,test\n",
    "\n",
    "def splitandtrain(df,thresh):\n",
    "    train,test = StratifiedSampling(df, 0.5)\n",
    "    train_x = list(train.wordvec)\n",
    "    train_y = list(train.y)\n",
    "    valid_x = list(test.wordvec)\n",
    "    valid_y = list(test.y)\n",
    "    report_list = train_classifier(train_x, train_y, valid_x,valid_y,thresh)\n",
    "    return report_list\n",
    "\n",
    "#get average classification stats by running split and train for 10 times. \n",
    "####cluster_df_1: a dataset df including training and testing\n",
    "####thresh: probability threshold\n",
    "def ave_score(cluster_df_1, thresh):\n",
    "    for i in range(10):\n",
    "        flag = test_classifiers_flag[0]\n",
    "        report = splitandtrain(cluster_df_1[['y','wordvec']],thresh)[0]\n",
    "        precision_list.append(report[1]['1']['precision'])\n",
    "        recall_list.append(report[1]['1']['recall'])\n",
    "        f1_list.append(report[1]['1']['f1-score'])\n",
    "        accuracy_list.append(report[1]['accuracy'])\n",
    "    print('-----------------',thresh,'-------------------')\n",
    "    print('precision:', sum(precision_list)/len(precision_list))\n",
    "    print('recall:', sum(recall_list)/len(recall_list))\n",
    "    print('f1:', sum(f1_list)/len(f1_list))\n",
    "    print('accuracy:', sum(accuracy_list)/len(accuracy_list))\n",
    "    return sum(precision_list)/len(precision_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#classification methods\n",
    "RF = RandomForestClassifier()\n",
    "LR = LogisticRegressionCV(cv=5, random_state=0,max_iter=1000)\n",
    "test_classifiers = [RF,LR]\n",
    "test_classifiers_flag = ['RF','LR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#pick the class for binary classification and prepare training data\n",
    "bilabel = [1 if i==3 else 0 for i in list(cluster_df_sample_6x100.true_class)]\n",
    "selected_class_num = sum(bilabel)\n",
    "for_join = cluster_df_sample_6x100[['combined_tweet_txt']]\n",
    "cluster_df_1 = for_join.set_index('combined_tweet_txt').join(lstm_pred_negative.set_index('combined_tweet_txt'), how='left')\n",
    "cluster_df_1['y'] = bilabel\n",
    "selected_class_tweets = cluster_df_1[cluster_df_1.y == 1]\n",
    "other_class_tweets = cluster_df_1[cluster_df_1.y == 0]\n",
    "cluster_df_1 = selected_class_tweets.append(other_class_tweets.sample(selected_class_num))\n",
    "#RF_report,LR_report = splitandtrain(cluster_df_1[['y','wordvec']],0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------- 0.30000000000000004 -------------------\n",
      "precision: 0.4780811265109791\n",
      "recall: 0.8486111111111111\n",
      "f1: 0.6115575780600402\n",
      "accuracy: 0.46482758620689657\n",
      "0.4780811265109791\n",
      "----------------- 0.4 -------------------\n",
      "precision: 0.4940050912340362\n",
      "recall: 0.8034722222222224\n",
      "f1: 0.6106540068638461\n",
      "accuracy: 0.49137931034482757\n",
      "0.4940050912340362\n",
      "----------------- 0.5 -------------------\n",
      "precision: 0.5206590550377658\n",
      "recall: 0.7319444444444445\n",
      "f1: 0.6006445330227131\n",
      "accuracy: 0.5202298850574713\n",
      "0.5206590550377658\n",
      "----------------- 0.6000000000000001 -------------------\n",
      "precision: 0.5768116761114345\n",
      "recall: 0.6416666666666667\n",
      "f1: 0.5740936906907382\n",
      "accuracy: 0.546206896551724\n",
      "0.5768116761114345\n",
      "----------------- 0.7000000000000001 -------------------\n",
      "precision: 0.6314145111677854\n",
      "recall: 0.5558333333333332\n",
      "f1: 0.5272386181005256\n",
      "accuracy: 0.5550344827586206\n",
      "0.6314145111677854\n",
      "----------------- 0.8 -------------------\n",
      "precision: 0.6759795603572887\n",
      "recall: 0.48402777777777767\n",
      "f1: 0.4758282690708265\n",
      "accuracy: 0.5556321839080459\n",
      "0.6759795603572887\n",
      "----------------- 0.9 -------------------\n",
      "precision: 0.7186967660205331\n",
      "recall: 0.42480158730158707\n",
      "f1: 0.42635422544934987\n",
      "accuracy: 0.5530049261083746\n",
      "0.7186967660205331\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'precision')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot Threshold Precision Correlation\n",
    "test_classifiers = [RF]\n",
    "test_classifiers_flag = ['RF']\n",
    "precision_list, recall_list, f1_list, accuracy_list = [],[],[],[]\n",
    "precision_line,thresh_line = [],[]\n",
    "\n",
    "#find threshold correlation with precision\n",
    "for j in range(7):\n",
    "    thresh = 0.1*(j+3)\n",
    "    thresh_line.append(thresh)\n",
    "    precision = ave_score(cluster_df_1, thresh)\n",
    "    precision_line.append(precision)\n",
    "    print(precision)\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "plt.plot(thresh_line,precision_line)\n",
    "fig.suptitle('Threshold Precision Correlation '+test_classifiers_flag[0], fontsize=16)\n",
    "plt.xlabel('threshold', fontsize=16)\n",
    "plt.ylabel('precision', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Active learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#biclass classification for active learning\n",
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid,valid_y,thresh):\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    predicted_proba = classifier.predict_proba(feature_vector_valid)\n",
    "    predictions = (predicted_proba [:,1] >= thresh).astype('int')\n",
    "    \n",
    "    labels = np.unique(label)\n",
    "\n",
    "    report = classification_report(valid_y,predictions,labels = labels,output_dict =True)\n",
    "    \n",
    "    return report,classifier\n",
    "\n",
    "def train_classifier(X_train, y_train, X_valid,valid_y,thresh):\n",
    "    report_list=[]\n",
    "    for classifier, flag in zip(test_classifiers, test_classifiers_flag):\n",
    "        report,classifier=train_model(classifier, X_train, y_train, X_valid,valid_y,thresh)\n",
    "        #print('------------------The report of',flag,'--------------------')\n",
    "        #print(report)\n",
    "        #print(conf)\n",
    "        report_list.append((flag,report))\n",
    "    return report_list,classifier\n",
    "\n",
    "def StratifiedSampling(df, test_size):\n",
    "    X = df.drop(['y'], axis=1)\n",
    "    y = df.y\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, test_size=test_size, random_state=0)    \n",
    "    sss.get_n_splits(X, y)\n",
    "    for train_index, test_index in sss.split(X, y):\n",
    "        train = df.iloc[train_index,:]\n",
    "        test = df.iloc[test_index,:]\n",
    "    return train,test\n",
    "\n",
    "def splitandtrain(df,thresh):\n",
    "    train,test = StratifiedSampling(df, 0.5)\n",
    "    train_x = list(train.wordvec)\n",
    "    train_y = list(train.y)\n",
    "    valid_x = list(test.wordvec)\n",
    "    valid_y = list(test.y)\n",
    "    report_list,classifier = train_classifier(train_x, train_y, valid_x,valid_y,thresh)\n",
    "    return report_list,classifier\n",
    "\n",
    "def ave_score(cluster_df_1, thresh):\n",
    "    for i in range(10):\n",
    "        flag = test_classifiers_flag[0]\n",
    "        report, classifier = splitandtrain(cluster_df_1[['y','wordvec']],thresh)\n",
    "        report = report[0]\n",
    "        #print(report)\n",
    "        precision_list.append(report[1]['1']['precision'])\n",
    "        recall_list.append(report[1]['1']['recall'])\n",
    "        f1_list.append(report[1]['1']['f1-score'])\n",
    "        accuracy_list.append(report[1]['accuracy'])\n",
    "    #print(thresh)\n",
    "    #print('precision:', sum(precision_list)/len(precision_list))\n",
    "    #print('recall:', sum(recall_list)/len(recall_list))\n",
    "    #print('f1:', sum(f1_list)/len(f1_list))\n",
    "    #print('accuracy:', sum(accuracy_list)/len(accuracy_list))\n",
    "    return sum(precision_list)/len(precision_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pick the class for binary classification and prepare training data\n",
    "bilabel = [1 if i==3 else 0 for i in list(cluster_df_sample_6x100.true_class)]\n",
    "selected_class_num = sum(bilabel)\n",
    "for_join = cluster_df_sample_6x100[['combined_tweet_txt']]\n",
    "#perform join to get wordvec \n",
    "cluster_df_1 = for_join.set_index('combined_tweet_txt').join(lstm_pred_negative.set_index('combined_tweet_txt'), how='left')\n",
    "cluster_df_1['y'] = bilabel\n",
    "selected_class_tweets = cluster_df_1[cluster_df_1.y == 1]\n",
    "other_class_tweets = cluster_df_1[cluster_df_1.y == 0]\n",
    "cluster_df_1 = selected_class_tweets.append(other_class_tweets.sample(selected_class_num))\n",
    "#get the trained classifier for classification \n",
    "report, classifier= splitandtrain(cluster_df_1[['y','wordvec']],0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "report, classifier= splitandtrain(cluster_df_1[['y','wordvec']],0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('RF',\n",
       "  {'0': {'precision': 0.58,\n",
       "    'recall': 0.7945205479452054,\n",
       "    'f1-score': 0.6705202312138728,\n",
       "    'support': 73},\n",
       "   '1': {'precision': 0.6666666666666666,\n",
       "    'recall': 0.4166666666666667,\n",
       "    'f1-score': 0.5128205128205129,\n",
       "    'support': 72},\n",
       "   'accuracy': 0.6068965517241379,\n",
       "   'macro avg': {'precision': 0.6233333333333333,\n",
       "    'recall': 0.605593607305936,\n",
       "    'f1-score': 0.5916703720171929,\n",
       "    'support': 145},\n",
       "   'weighted avg': {'precision': 0.6230344827586207,\n",
       "    'recall': 0.6068965517241379,\n",
       "    'f1-score': 0.5922141641495837,\n",
       "    'support': 145}})]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-136-47fb8c52d047>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  lstm_pred_negative_long['diff_to_thresh'] = diff_to_thresh\n"
     ]
    }
   ],
   "source": [
    "#classification on the trained dataset\n",
    "predicted_proba = classifier.predict_proba(list(lstm_pred_negative_long['wordvec']))[:,1]\n",
    "diff_to_thresh = [abs(i-0.6) for i in predicted_proba]\n",
    "lstm_pred_negative_long['diff_to_thresh'] = diff_to_thresh\n",
    "lstm_pred_negative_long = lstm_pred_negative_long.sort_values(by=['diff_to_thresh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ambiguous = lstm_pred_negative_long.head(100)\n",
    "top_ambiguous = top_ambiguous.set_index('tweet_id').join(all_df.set_index('tweet_id'), how='left')\n",
    "top_ambiguous.to_excel('top_ambiguous_1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ambiguous_labeled = pd.read_excel(r\"C:\\Users\\luoyu\\Desktop\\USCISI\\vaccine hesitancy\\top_ambiguous.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_sample = cluster_df_sample_6x100[['combined_tweet_txt','true_class']].append(top_ambiguous_labeled[['combined_tweet_txt','true_class']])\n",
    "#pick the class for binary classification and prepare training data\n",
    "#merged_sample = top_ambiguous_labeled[['combined_tweet_txt','true_class']]\n",
    "bilabel = [1 if i==3 else 0 for i in list(merged_sample.true_class)]\n",
    "selected_class_num = sum(bilabel)\n",
    "for_join = merged_sample[['combined_tweet_txt']]\n",
    "#perform join to get wordvec \n",
    "cluster_df_1 = for_join.set_index('combined_tweet_txt').join(lstm_pred_negative.set_index('combined_tweet_txt'), how='left')\n",
    "cluster_df_1['y'] = bilabel\n",
    "selected_class_tweets = cluster_df_1[cluster_df_1.y == 1]\n",
    "other_class_tweets = cluster_df_1[cluster_df_1.y == 0]\n",
    "cluster_df_1 = selected_class_tweets.append(other_class_tweets.sample(selected_class_num))\n",
    "#get the trained classifier for classification \n",
    "report, classifier = splitandtrain(cluster_df_1[['y','wordvec']],0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5000750586579185"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_list, recall_list, f1_list, accuracy_list = [],[],[],[]\n",
    "ave_score(cluster_df_1, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 0.4878048780487805,\n",
       " 'recall': 0.22988505747126436,\n",
       " 'f1-score': 0.3125,\n",
       " 'support': 87}"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report[0][1]['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "bilabel = [1 if i==3 else 0 for i in list(merged_sample.true_class)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(bilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
